#!/usr/bin/python3
from openai import OpenAI, InternalServerError
from pathlib import Path
from subprocess import Popen, PIPE
import argparse
from mutagen.mp3 import MP3
from moviepy import editor
import os
import requests
from tempfile import NamedTemporaryFile
import validators
from urllib.request import urlopen
from bs4 import BeautifulSoup
import sys

class VideoBlock:
    def __init__(self, client, paragraph_input):
        self.client = client
        self.text = paragraph_input
        self.audio = None
        self.image = None
        self.video = None

    def choose_image(self, fname):
        # Is it a url, or a local filename?
        if check_url(fname):
            img_data = requests.get(fname).content
            with NamedTemporaryFile('w', delete=False) as t:
                self.image = t.name
            with open(self.image, 'wb') as w:
                w.write(img_data)
        elif os.path.exists(fname):
            self.image = fname

    def generate_image(self):
        # Generate images until the user decides it is sufficient
        try:
            response = self.client.images.generate(
              model="dall-e-3",
              prompt='Digital art that envisions the following prompt: "%s"' % self.text,
              size="1792x1024",
              quality="standard",
              n=1,
            )
        except InternalServerError:
            sys.stderr.write('Image failed to generate\n')
            return
        image_url = response.data[0].url
        img_data = requests.get(image_url).content
        with NamedTemporaryFile('w', delete=False, suffix='.png') as t:
            self.image = t.name
        with open(self.image, 'wb') as w:
            w.write(img_data)

    def generate_audio(self):
        # Generate the spoken audio
        try:
            response = self.client.audio.speech.create(
              model="tts-1",
              voice="alloy",
              input=self.text
            )
        except InternalServerError:
            sys.stderr.write('Audio failed to generate\n')
            return
        with NamedTemporaryFile('w', delete=False, suffix='.mp3') as t:
            response.stream_to_file(t.name)
            self.audio = t.name

    def generate_video(self):
        video = editor.ImageClip(self.image)
        audio = MP3(self.audio)
        audio_length = audio.info.length
        video.duration = audio_length
        audio = editor.AudioFileClip(self.audio)
        final_video = video.set_audio(audio)
        with NamedTemporaryFile('w', delete=False, suffix='.mp4') as t:
            self.video = t.name
        final_video.write_videofile(fps=1, codec="mpeg4", filename=self.video)

    def cleanup(self):
        # TODO: Delete the audio and image files.
        pass

content_comment = """###############################################################
# The following is the generated lesson content.
# Make any necessary changes to the text prior to proceeding.
# Designate sections by spliting them up by two newlines
# ('\\n\\n'). Each section will be paired with a matching
# image. The more sections you specify, the more images will
# be generated (and the more specific the images will be).
###############################################################

"""

prompt_comment = """###############################################################
# The following is your input prompt.
# Designate sections by spliting them up by two newlines
# ('\\n\\n'). The smaller you split the sections, the more
# response text can be generated. Do NOT add two newlines
# between headings and paragraphs. Always ensure these are
# together in the same block.
###############################################################

"""

def generate_lesson(prompt, openai_key, prompt_msg, output_filename):
    client = OpenAI(api_key=openai_key)
    # Manually verify the prompt input
    with NamedTemporaryFile('w') as t:
        t.write(prompt_comment+prompt)
        t.flush()
        Popen(['vim', t.name]).wait()
        t.flush()
        with open(t.name, 'r') as r:
            prompt = r.read().replace(prompt_comment, '')
    # Split up the prompt by paragraph.
    final_content = []
    for prompt_paragraph in prompt.split('\n\n'):
        main_content = prompt_message(client, prompt_msg+prompt_paragraph)
        with NamedTemporaryFile('w') as t:
            t.write(content_comment+main_content)
            t.flush()
            Popen(['vim', t.name]).wait()
            t.flush()
            with open(t.name, 'r') as r:
                main_content = r.read().replace(content_comment, '')
        final_content.append(VideoBlock(client, main_content))
    for content in final_content:
        print(content.text)
        resp = input('Would you like to choose an existing image? (y/N) ').strip().lower() or 'n'
        if resp.startswith('y'):
            fname = input('Choose a filename: ').strip()
            content.choose_image(fname)
            if content.image:
                continue
            else:
                print('Image not found')
        print('Generating an image for this text...')
        resp = 'n'
        while resp.startswith('n'):
            content.generate_image()
            Popen(['google-chrome', content.image])
            resp = input('Is this image sufficient? (Y/n) ').strip().lower() or 'y'
    print('Generating audio...')
    for content in final_content:
        content.generate_audio()
    print('Generating video...')
    for content in final_content:
        content.generate_video()
    append_videos(final_content, output_filename)
    print('Video created successfully!')

def append_videos(final_content, output_filename):
    if not output_filename.endswith('.mp4'):
        output_filename = output_filename + '.mp4'
    video_files = [editor.VideoFileClip(c.video) for c in final_content]
    final_clip = editor.concatenate_videoclips(video_files)
    final_clip.to_videofile(output_filename, fps=1)

    for content in final_content:
        content.cleanup()

def prompt_message(client, prompt):
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": prompt,
            }
        ],
        model="gpt-3.5-turbo",
    )
    return chat_completion.choices[0].message.content

def check_url(prompt):
    # Check if the input prompt is actually a url
    return validators.url(prompt)

if __name__ == '__main__':
    openai_key = None
    if os.path.exists('./openai.key'):
        openai_key = open('./openai.key', 'r').read().strip()
    parser = argparse.ArgumentParser(description='A simple lesson generator using openAI')
    parser.add_argument('prompt', help='Either a prompt, an input filename, or a url')
    parser.add_argument('output', help='Output video file name')
    parser.add_argument('--openai-key', help='OpenAI key for authenticating to the service', default=openai_key)
    parser.add_argument('--age', help='The age of the audiance', type=int, default=10)
    args = parser.parse_args()
    if args.openai_key is None:
        print('An OpenAI key is mandatory to proceed.')
        exit(1)
    # Is the prompt actually a filename?
    audiance_type = 'a child' if args.age < 18 else 'an adult'
    prompt_msg = 'Reword and summarize the following content for %s aged %d: ' % (audiance_type, args.age)
    if check_url(args.prompt):
        html = urlopen(args.prompt).read()
        soup = BeautifulSoup(html, features="html.parser")
        for script in soup(["script", "style"]):
            script.extract()
        prompt = soup.get_text()
    elif os.path.exists(args.prompt):
        prompt = open(args.prompt, 'r').read()
    else:
        prompt_msg = 'Phrase your response for %s aged %d. ' % (audiance_type, args.age)
        prompt = args.prompt

    generate_lesson(prompt, args.openai_key, prompt_msg, args.output)
